{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Practical HPC</center>\n",
    "<p>\n",
    "## <center>Robert Bjornson</center> \n",
    "<p>\n",
    "## <center><i>Yale Center for Research Computing</i></center>\n",
    "<p>\n",
    "## <center>March 2018</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Yale Center for Research Computing?\n",
    "\n",
    "\n",
    "- Independent center under the Provost's office\n",
    "- Created to support your research computing needs\n",
    "- Focus is on high performance computing and storage\n",
    "- ~15 staff, including applications specialists and system engineers\n",
    "- Available to consult with and educate users\n",
    "- Manage compute clusters and support users\n",
    "- Located at 160 St. Ronan st, at the corner of Edwards and St. Ronan\n",
    "- http://research.computing.yale.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Understanding the HPC environment\n",
    "- Understanding your program's behavior\n",
    "- Improving performance\n",
    "- Running parallel programs\n",
    "- Creating parallel programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions\n",
    "- Have logged in to a cluster and run simple jobs\n",
    "- understand basics of Slurm\n",
    "- want to run more effectively and efficiently\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The HPC Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is HPC?\n",
    "- running jobs remotely on a compute cluster \n",
    "- linux-based\n",
    "- using more compute resources (cpus/memory) than you have locally\n",
    "- access to huge shared storage\n",
    "- access to specialized hardware, e.g. GPUs \n",
    "- access to specialized software\n",
    "- running large job in parallel, or many sequential jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![alt text](clusterschematic.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typical Cluster\n",
    "\n",
    "![alt text](yalecluster.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typical compute node\n",
    "![alt text](nx360-M5.jpg \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical Cluster (Yale, or elsewhere)\n",
    "- Several hundred servers (nodes)\n",
    "- Each node has 10s of cpus -> Thousands of total cpus\n",
    "- Each node has 100s of GB RAM\n",
    "- Multiple PB of shared storage\n",
    "- Fast network connecting nodes and networks\n",
    "- Shared by 100s of users, 1000s of jobs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Resources\n",
    "These are managed by slurm, cgroups, and storage quotas\n",
    "- Nodes and CPUs\n",
    "- Node Memory (RAM)\n",
    "- Job Runtime\n",
    "- Cluster Disk Storage\n",
    "- GPUs\n",
    "\n",
    "### Note\n",
    "- jobs (unrelated) normally share nodes.  Slurm+cgroups makes sure you have\n",
    "exclusive access to your resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Review of Slurm allocations\n",
    "\n",
    "$ sbatch [options] batch.sh\n",
    "\n",
    "$ srun --pty [options] bash\n",
    "\n",
    "option | example | comment\n",
    "-------|--------|---\n",
    "-p _partition_ | -p general | partitions(s) to run on\n",
    "-c _cpus_ | -c 20 | cpus/task on single node\n",
    "-n _tasks_ | -n 4 | mpi progs only\n",
    "-N _nodes_ | -N 10 | forces layout, rarely useful\n",
    "-t _time_  | -t 7-, -t 3:00 | job killed if exceeded\n",
    "--mem=_mem_ | --mem=16g | ditto\n",
    "--mem-per-cpu=_mem_ | --mem-per-cpu=8g | ditto\n",
    "-J _name_ | -J myjob | name job\n",
    "--gres | --gres=gpu:p100:2 | request gpus\n",
    "--array _spec_ | --array 1-10 | array job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairshare Scheduling with backfill\n",
    "- Slurm tracks cpu usage by user and group\n",
    "- Job priority is determined by amount of recent usage\n",
    "- Users and Groups with heavy recent usage have lower priority\n",
    "- Backfill can run short, lower priority jobs\n",
    "- Bottom line: only ask for what you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes/CPUs\n",
    "- default: 1 node, 1 cpu\n",
    "- only request multiple cpus and/or nodes if your program can use them\n",
    "- simply requesting more nodes or cpus will not make things run faster!\n",
    "- cgroups pens you into your allocated cpus\n",
    "- understand -c (--cpus-per-task)\n",
    "     vs -n (--ntasks) vs -N (--nodes)\n",
    "- only request GPU or bigmem nodes if you need them\n",
    "- users have limits (e.g. 100 cpus)\n",
    "- -C _type_ (westmere, haswell, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    "- default of 5 GB per allocated cpu on our clusters\n",
    "- strictly enforced; jobs exceeding limit are killed\n",
    "- users have limits (e.g. 640 GB)\n",
    "- you can request custom memory per node or core with sbatch or srun:\n",
    "```\n",
    "--mem=6g\n",
    "--mem-per-cpu=6g\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Compute Resources\n",
    "\n",
    "To get overall sense:\n",
    "```\n",
    "sinfo -p general\n",
    "```\n",
    "To see completely idle nodes, by core count:\n",
    "\n",
    "```\n",
    "$ sinfo -p general -e -t IDLE -o \"%P %.5a %c %m %.10l %.6D %.6t %N\"\n",
    "PARTITION AVAIL CPUS  TIMELIMIT  NODES  STATE NODELIST\n",
    "general*    up 8 30-00:00:0     35   idle c06n[10-16],c07n[01-14,16],c08n[01-06,08-14]\n",
    "general*    up 16 30-00:00:0     23   idle c10n[13-16],c11n[01-16],c12n[09-11]\n",
    "```\n",
    "\n",
    "Hint, use alias:\n",
    "```\n",
    "alias findidle='sinfo -e -t IDLE -o \"%P %.5a %c %m %.10l %.6D %.6t %N\"'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST\n",
      "general*     up 30-00:00:0      4  drain c14n[01-04]\n",
      "general*     up 30-00:00:0     81    mix c06n[10-15],c07n[01-03,12],c10n[14-15],c11n[01,05-06,09,11,13-16],c12n[02-04,10-11],c13n[01-04,09-10],c14n[06-11],c15n[02,04-05,07-11],c16n[01-02,04,07-11],c18n[01-02,04-05,08-10],c19n[02-03,05,11-12],c20n[01-03,05-06,08-09],c21n[05-07],c22n01,c23n[08-10,12]\n",
      "general*     up 30-00:00:0     51  alloc c07n08,c10n13,c11n[02-04,08,10,12],c12n[07-08,12-13],c13n[05-08,11-12],c14n[05,12],c15n[01,03,06,12],c16n[03,05-06,12],c18n[03,06-07,11-12],c19n[01,04,06-10],c20n[04,07,10-12],c21n[01-04],c22n03,c23n11\n",
      "general*     up 30-00:00:0     31   idle c06n[09,16],c07n[04-07,09-11,13-14,16],c08n[01-06,08-14],c10n16,c11n07,c12n[05-06,09],c22n02\n"
     ]
    }
   ],
   "source": [
    "# get status on partition\n",
    "sinfo -p general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITION AVAIL CPUS MEMORY  TIMELIMIT  NODES  STATE NODELIST\n",
      "general*    up 8 44032 30-00:00:0     25   idle c06n[09,16],c07n[04-07,09-11,13-14,16],c08n[01-06,08-14]\n",
      "general*    up 16 123904 30-00:00:0      5   idle c10n16,c11n07,c12n[05-06,09]\n",
      "general*    up 20 123904 30-00:00:0      1   idle c22n02\n"
     ]
    }
   ],
   "source": [
    "# find idle nodes\n",
    "sinfo -p general -e -t IDLE -o \"%P %.5a %c %m %.10l %.6D %.6t %N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITION AVAIL CPUS MEMORY  TIMELIMIT  NODES  STATE NODELIST\n",
      "general*    up 8 44032 30-00:00:0     25   idle c06n[09,16],c07n[04-07,09-11,13-14,16],c08n[01-06,08-14]\n",
      "general*    up 16 123904 30-00:00:0      5   idle c10n16,c11n07,c12n[05-06,09]\n"
     ]
    }
   ],
   "source": [
    "# Hint, use alias\n",
    "alias findidle='sinfo -e -t IDLE -o \"%P %.5a %c %m %.10l %.6D %.6t %N\"'\n",
    "findidle -p general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical Tools\n",
    "\n",
    "http://overwatch.ycrc.yale.edu/farnam/orwell/\n",
    "\n",
    "http://overwatch.ycrc.yale.edu/grace/orwell/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scavenge Partition\n",
    "```\n",
    "$ sbatch -p scavenge\n",
    "```\n",
    "\n",
    "- Compute nodes in other partions are available via scavenge partition\n",
    "- jobs subject to being killed at any time\n",
    "- separate per user limits apply\n",
    "- works best for short jobs, dSQ/array jobs, or jobs that checkpoint\n",
    "- can include gpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Memory Nodes\n",
    "- Compute nodes with 512GB-1.5TB of RAM\n",
    "- Reserved for applications with large memory needs. Please be considerate.\n",
    "- Separate slurm partition: bigmem\n",
    "\n",
    "Typical allocation: \n",
    "```\n",
    "srun/sbatch -p bigmem --mem=1500g ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Nodes\n",
    "- Some applications have been ported to GPUs with impressive performance improvement\n",
    "- Gpu nodes have conventional cpus with multiple cores, and 1-4 GPUs.  \n",
    "- To use GPUs, you must:\n",
    " - request node(s) with GPUs\n",
    " - request the type and number of GPUs \n",
    "\n",
    "Typical allocation:\n",
    "```\n",
    "srun --pty -p gpu -c 8 --gres=gpu:1080ti:4 ... bash\n",
    "sbatch -p gpu -c 8 --gres=gpu:1080ti:4 ... batch.sh\n",
    "```\n",
    "\n",
    "You can also scavenge gpu nodes:\n",
    "```\n",
    "srun --pty -p scavenge -c 8 --gres=gpu:1080ti:4 ... bash\n",
    "sbatch -p scavenge -c 8 --gres=gpu:1080ti:4 ... batch.sh\n",
    "```\n",
    "\n",
    "Note that partition names, types and number of GPUs vary by cluster.\n",
    "\n",
    "Type | FP | Clusters\n",
    "-------|--------|---\n",
    "1080ti | single | farnam\n",
    "K80 | double | grace,farnam\n",
    "P100 | double | grace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Job's Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is \"Running Efficiently\"?\n",
    "- All allocated cores are running near 100%\n",
    "- GPUs (if allocated) are used\n",
    "- memory requested is adequate and reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring your job\n",
    "```\n",
    "squeue -u netid -l (your jobs)\n",
    "squeue -j jobid -l (particular job)\n",
    "scontrol show job jobid (during job)\n",
    "sacct -j jobid -l (after job finishes)\n",
    "```\n",
    "Default output for squeue and sacct is not ideal.  Put in .bashrc:\n",
    "```\n",
    "export SACCT_FORMAT=\"JobID%-20,JobName,User,Partition,NodeList,Elapsed,State,ExitCode,MaxRSS, AllocTRES%32\"\n",
    "export SQUEUE_FORMAT=\"%.16i %.12P %.12j %.8u %.2t %.12M %.12l %24R %.4D %.4C %m %8b %8f\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking cpu and memory utilization for running jobs\n",
    "Using top/htop\n",
    "- use ```squeue -u netid``` to determine where your job is running\n",
    "- ssh to your nodes, especially 2nd and on, and run ```top -u netid``` \n",
    "    (or ```htop```)\n",
    "- look at %CPU and RES columns\n",
    "- should see ~%100 cpu for each allocated core\n",
    "EXAMPLE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postmortem checking\n",
    "\n",
    "1. Run program under /usr/bin/time\n",
    "```\n",
    "$ /usr/bin/time -a myprog arg1 arg2 ...\n",
    "```\n",
    "\n",
    "2. After run completes, determine actual usage (See format comment):\n",
    "```\n",
    "$ sacct -j jobid\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example: Performance\n",
    "```\n",
    "cd Examples/Performance\n",
    "sbatch -c 1 bwa.sh # runs out of RAM (default 5GB/core)\n",
    "sbatch -c 10 --mem=5g bwa.sh # also runs out\n",
    "sbatch -c 10 # runs ok.  Show htop, scontrol, sacct, \n",
    "Htop: H combines threads.  F5 shows tree\n",
    "sacct -j jobid\n",
    "control show job jobid\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Storage Quotas\n",
    "- most quotas are group quotas\n",
    "- if exceeded, jobs will die trying to write\n",
    "- to see all quotas for your group:\n",
    "```\n",
    "$ groupquota #(e.g. as be59)\n",
    "```\n",
    "\n",
    "## File Storage\n",
    "\n",
    "Location | Purpose | Typical Limit (size/files)| Backed Up?\n",
    "-------|--------|---|----|\n",
    "home | scripts, programs, documents, small files | 125GB/500K | Y\n",
    "project | large data, programs | 1-4TB/5M | N \n",
    "scratch60 | temp data | 10TB/5M | purged\n",
    "pi\\__name_ | dedicated | _varies_ | N\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Transfer\n",
    "- For small transfers: \n",
    " - Linux/Mac/cygwin: scp, rsync\n",
    " - Windows: Mobaxterm, winscp\n",
    " \n",
    " \n",
    "- For larger transfers, or outside Yale, or collaborators without Yale credentials:\n",
    " - Globus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globus\n",
    "- www.globus.org\n",
    "- web and command line\n",
    "- very fast and robust\n",
    "- transfers between _endpoints_\n",
    "- endpoints: \n",
    " - Yale clusters: yale#{cluster}\n",
    " - Lots of other institutions\n",
    " - personal endpoint on your own computer\n",
    "- you can create _shares_, accessible to non-Yale researchers via their globus id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](globus.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "```\n",
    "show personal endpoint (RobsGlobus)\n",
    "show creating share and sharing with jason.ignatius@yale.edu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globus cli\n",
    "```\n",
    "$ module load Globus-CLI\n",
    "$ globus login\n",
    "(you'll get a url.  Open that in a browser, authenticate, and copy the code.  Enter the code on command line.)\n",
    "$ globus endpoint search RobsGlobus\n",
    "$ globus endpoint search yale#grace\n",
    "(set env vars to R and G)\n",
    "$ globus ls -l $R:/\n",
    "$ globus transfer -r -s size $R:data $G:tmp/data\n",
    "(returns taskid)\n",
    "$ globus task show taskid\n",
    "```\n",
    "https://docs.globus.org/cli/examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance\n",
    "- when possible, use optimized libraries, rather than roll your own\n",
    "- Python: numpy or pandas instead of nested lists for matrices\n",
    "- R, Matlab: vectors instead of loops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "- Helps you pinpoint where time is spent\n",
    "\n",
    " - R: Rprof\n",
    " - Python: cProfile, kernprof/line_profiler\n",
    " - C: gprof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python: cProfile for function level profiling\n",
    "```\n",
    "cd Examples/Profiling\n",
    "module load Python\n",
    "(get compute node with srun, module load Python)\n",
    "python -m cProfile -o bad.prof bad.py\n",
    "(takes a minute or two)\n",
    "\n",
    "(in python)\n",
    "import pstats\n",
    "p=pstats.Stats('prof.out')\n",
    "p.sort_stats('time').print_stats()\n",
    "\n",
    "or \n",
    "\n",
    "```\n",
    "\n",
    "## kernprof for line-by-line\n",
    "```\n",
    "module load Python\n",
    "(decorate functions with @profile)\n",
    "kernprof -l bad2.py\n",
    "python -m line_profiler  bad2.py.lprof\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 18 09:04:59 2018    bad.prof\n",
      "\n",
      "         685534 function calls (685533 primitive calls) in 91.130 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    71520   90.087    0.001   90.087    0.001 {method 'index' of 'list' objects}\n",
      "        1    0.577    0.577   91.114   91.114 bad.py:9(annotate)\n",
      "    71520    0.238    0.000    0.238    0.000 {built-in method builtins.print}\n",
      "   152442    0.113    0.000    0.113    0.000 {method 'split' of 'str' objects}\n",
      "    71558    0.040    0.000    0.040    0.000 {method 'join' of 'str' objects}\n",
      "   152442    0.029    0.000    0.029    0.000 {method 'strip' of 'str' objects}\n",
      "        1    0.016    0.016   91.130   91.130 bad.py:5(<module>)\n",
      "   161844    0.012    0.000    0.012    0.000 {method 'append' of 'list' objects}\n",
      "     1886    0.007    0.000    0.013    0.000 /ysm-gpfs/home/rdb9/Installed/anaconda3/lib/python3.5/codecs.py:318(decode)\n",
      "     1886    0.006    0.000    0.006    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        3    0.003    0.001    0.004    0.001 {built-in method io.open}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "        7    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1215(find_spec)\n",
      "       36    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:52(<listcomp>)\n",
      "       36    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:50(_path_join)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1101(_get_spec)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:816(get_data)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method marshal.loads}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
      "       34    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 /ysm-gpfs/home/rdb9/Installed/anaconda3/lib/python3.5/_bootlocale.py:23(getpreferredencoding)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'read' of '_io.FileIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:879(_find_spec)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'find_loader' of 'zipimport.zipimporter' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /ysm-gpfs/home/rdb9/Installed/anaconda3/lib/python3.5/__future__.py:48(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:729(get_code)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
      "      2/1    0.000    0.000   91.130   91.130 {built-in method builtins.exec}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:474(_compile_bytecode)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:246(cache_from_source)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:419(_validate_bytecode_header)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:510(_init_module_attrs)\n",
      "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:68(_path_stat)\n",
      "       74    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:56(_path_split)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
      "       11    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1064(_path_importer_cache)\n",
      "        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap>:966(_find_and_load)\n",
      "        1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap>:939(_find_and_load_unlocked)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1086(_legacy_get_spec)\n",
      "       13    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:94(acquire)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:176(_get_module_lock)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:321(__exit__)\n",
      "       36    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:366(_verbose_message)\n",
      "        9    0.000    0.000    0.000    0.000 /ysm-gpfs/home/rdb9/Installed/anaconda3/lib/python3.5/__future__.py:79(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:659(_load_unlocked)\n",
      "        2    0.000    0.000    0.000    0.000 /ysm-gpfs/home/rdb9/Installed/anaconda3/lib/python3.5/codecs.py:308(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:342(_get_cached)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:372(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:570(module_from_spec)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:74(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:659(exec_module)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:856(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:513(spec_from_file_location)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:119(release)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:852(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:163(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:406(cached)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:45(_r_long)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:214(_call_with_frames_removed)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:78(_path_is_mode_type)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:826(path_stats)\n",
      "        1    0.000    0.000    0.000    0.000 /ysm-gpfs/home/rdb9/Installed/anaconda3/lib/python3.5/codecs.py:185(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:786(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:324(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1210(_get_spec)\n",
      "        2    0.000    0.000    0.000    0.000 /ysm-gpfs/home/rdb9/Installed/anaconda3/lib/python3.5/codecs.py:259(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:789(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:996(_handle_fromlist)\n",
      "        1    0.000    0.000    0.000    0.000 /ysm-gpfs/home/rdb9/Installed/anaconda3/lib/python3.5/__future__.py:78(_Feature)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:310(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:159(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:314(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:190(cb)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:87(_path_isfile)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:419(parent)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1133(find_spec)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:382(_check_name_wrapper)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:716(find_spec)\n",
      "        7    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:34(_relax_case)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:170(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:656(create_module)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:811(get_filename)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:225(_verbose_message)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:427(has_location)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd ~/repos/PracticalHPC/Examples/Profiling\n",
    "#python -m cProfile -o bad.prof bad.py\n",
    "python -c \"import pstats; p=pstats.Stats('bad.prof'); p.sort_stats('time').print_stats()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 90.7797 s\n",
      "File: bad2.py\n",
      "Function: annotate at line 9\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     9                                           @profile\n",
      "    10                                           def annotate(gf, mf, of):\n",
      "    11         1        210.0    210.0      0.0      ofp=open(of, \"w\")\n",
      "    12         1          2.0      2.0      0.0      genenames=[]\n",
      "    13         1          0.0      0.0      0.0      geneinfo=[]\n",
      "    14     80923      60402.0      0.7      0.1      for l in open(gf):\n",
      "    15     80922     126776.0      1.6      0.1          gn, chrm, strand, start, end = l.strip().split()\n",
      "    16     80922      52296.0      0.6      0.1          genenames.append(gn)\n",
      "    17     80922      58058.0      0.7      0.1          geneinfo.append([chrm, strand, start, end])\n",
      "    18                                           \n",
      "    19     71521     170413.0      2.4      0.2      for l in open(mf):\n",
      "    20     71520     139256.0      1.9      0.2          e=l.strip().split()\n",
      "    21     71520      51000.0      0.7      0.1          genename=e[-1]\n",
      "    22     71520   89661196.0   1253.7     98.8          idx=genenames.index(genename)\n",
      "    23     71520     460062.0      6.4      0.5          print('\\t'.join(e + geneinfo[idx]), file=ofp)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd ~/repos/PracticalHPC/Examples/Profiling\n",
    "#kernprof -l bad2.py\n",
    "python -m line_profiler  bad2.py.lprof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "rdb9@c13n08 Profiling]$ python -m line_profiler bad2.py.lprof\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 114.565 s\n",
    "File: bad.py\n",
    "Function: doit at line 4\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     4                                           @profile\n",
    "     5                                           def doit(gf, mf, of):\n",
    "     6         1          134    134.0      0.0      ofp=open(of, \"w\")\n",
    "     7         1            1      1.0      0.0      genenames=[]\n",
    "     8         1            0      0.0      0.0      geneinfo=[]\n",
    "     9     80923        44421      0.5      0.0      for l in open(gf):\n",
    "    10     80922       105965      1.3      0.1          gn, chrm, strand, start, end = l.strip().split()\n",
    "    11     80922        44241      0.5      0.0          genenames.append(gn)\n",
    "    12     80922        49721      0.6      0.0          geneinfo.append([chrm, strand, start, end])\n",
    "    13\n",
    "    14     71521        90557      1.3      0.1      for l in open(mf):\n",
    "    15     71520       126260      1.8      0.1          genename=l.strip().split()[-1]\n",
    "    16\n",
    "    17     71520    110808166   1549.3     96.7          idx=genenames.index(genename)\n",
    "    18     71520      3295037     46.1      2.9          print(l + str(geneinfo[idx]), file=ofp)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIX: replace list with dictionary\n",
    "```\n",
    "kernprof -l good.py > /dev/null\n",
    "python -m line_profiler good.py.lprof\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism\n",
    "\n",
    "- Sbatch can allocate multiple cores and nodes, but the script runs on one core on one node sequentially.\n",
    "\n",
    "- _Simply allocating more nodes or cores DOES NOT make jobs faster._\n",
    "\n",
    "- How do we use multiple cores to increase speed?\n",
    "\n",
    "\n",
    "- Two classes of parallelism:\n",
    " - Lots of independent sequential jobs\n",
    " - Single job parallelized (somehow, maybe by someone else?)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, my \"Disclaimer\"\n",
    "- Parallel computing is a complex field with many tools and techniques\n",
    "- Entire courses: e.g. Yale CS 424/524 \"Parallel Programming Techniques\" by Dr. Andrew Sherman\n",
    "- We'll see some simple techniques for easy cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slurm Job Arrays\n",
    "\n",
    "- Useful when you have many nearly identical, independent jobs to run\n",
    "- Starts many identical copies of your script, distinguished by $SLURM_ARRAY_TASK_ID\n",
    "\n",
    "Submit jobs like this:\n",
    "```\n",
    "sbatch --array=1-100 script.sh\n",
    "```\n",
    "Inside your batch script this environment variable to do something different in each task:\n",
    "```\n",
    "./mycommand -i input.${SLURM_ARRAY_TASK_ID} \\\n",
    "    -o output.${SLURM_ARRAY_TASK_ID}\n",
    "```\n",
    "\n",
    "A few nice features of job arrays:\n",
    "- only one job to keep track of\n",
    "- easy to start or cancel entire set\n",
    "- slurm options, e.g. cpus, memory, time limits, apply to each task, not overall job\n",
    "- your allocation can grow and shrink as conditions change\n",
    "- when using scavenge partition, tasks are killed, but job persists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dSQ (aka Dead Simple Queue)\n",
    "- local tool built on job arrays.  Same nice features, but easier to use\n",
    "- more flexible; tasks can be arbitrarily different \n",
    "- reporting and error recovery built in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using dSQ\n",
    "\n",
    "\n",
    "- Create file containing list of commands to run (jobs.txt)\n",
    "```\n",
    "prog arg1 arg2 -o job1.out\n",
    "prog arg1 arg2 -o job2.out\n",
    "...\n",
    "```\n",
    "- Create batch script\n",
    "```\n",
    "module load dSQ\n",
    "dSQ --jobfile jobs.txt [slurm args] > run.sh\n",
    "```\n",
    "\n",
    "slurm args can specify partion, timelimit, memory, etc. in the usual way.\n",
    "\n",
    "- Submit launch script\n",
    "```\n",
    "sbatch run.sh\n",
    "```\n",
    "\n",
    "For more info, see <http://research.computing.yale.edu/support/hpc/user-guide/dead-simple-queue>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 6635264\n"
     ]
    }
   ],
   "source": [
    "cd ~/repos/PracticalHPC/Examples/GenomePL\n",
    "module load dSQ\n",
    "dSQ --jobfile tasks.sh > run.sh\n",
    "sbatch run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dSQ Reporting\n",
    "- When dSQ job is finished, you'll see a file `job_<jobid>_status.tsv`\n",
    "- Generate report:\n",
    "```\n",
    "$ dSQAutopsy jobs.txt job_<jobid>_status.tsv > failedjobs.txt\n",
    "Autopsy Task Report:\n",
    "9 succeeded\n",
    "1 failed\n",
    "0 didn't run.\n",
    "```\n",
    "\n",
    "- If any jobs failed, failedjobs.txt will contain those jobs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dSQ Example\n",
    "```\n",
    "cd Examples/GenomePL\n",
    "python mktasks.py data output > tasks.sh # create dSQ job file\n",
    "module load dSQ\n",
    "dSQ --jobfile tasks.sh > run.sh\n",
    "sbatch run.sh # will fail, do sacct -j jobid, resubmit --mem=10g\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running already parallelized applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel bootstrap in R using Multicore library\n",
    "- works on multiple cpus on one node\n",
    "\n",
    "```\n",
    "boot(data=trees, statistic=volume_estimate, R=50000, parallel=\"multicore\", ncpus=8)\n",
    "\n",
    "sbatch -c 8 ... script.sh\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Namd\n",
    "- molecular dynamics simulation written in C and C++\n",
    "- Namd is parallelized several ways, which can be combined:\n",
    " - OpenMP (within one node)\n",
    " - MPI (across nodes)\n",
    " - GPU\n",
    " \n",
    "Example: STMV virus 1,066,628 atoms, 500 time steps\n",
    "\n",
    "\n",
    "![alt text](Examples\\Namd\\namd.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Namd Performance on Grace\n",
    "\n",
    "   |startup (s)|simulate|total|step|step s/u\n",
    "---|-------|--------|-----|----|----\n",
    "1 node, 1 cpu|14|5833|5847|11.6|1.0\n",
    "1 node, 28 cpu|13|218|231|0.44|26.3\n",
    "1 node, 20 cpu+4 K80 gpus|12|32|44|.056|207\n",
    "9 nodes, 40 cpus|29.5|212|242|.424|27.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in /home/fas/lsprog/rdb9/repos/PracticalHPC/Examples/Namd/stmv\n",
    "- gpus slurm-9139008.out\n",
    "- mpi slurm-9152709.out\n",
    "- 28 core MP slurm-9139007.out\n",
    "- 1 core slurm-9140416.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# show \n",
    "- namd on 1 cpu\n",
    "- namd on 1 cpu asking for more\n",
    "- namd on several nodes\n",
    "memory required (while running, sacct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Kmeans in R using parallel\n",
    "\n",
    "- simple idea: reduce computation to applying function to list of values (very R-ish)\n",
    "- then do that in parallel\n",
    "\n",
    "sequential\n",
    "```\n",
    "starts=100000; tasks=8; nstarts=rep(starts/tasks, tasks)\n",
    "results<-lapply(nstarts, function(nstart) kmeans(Boston, 4, nstart=nstart)))\n",
    "```\n",
    "\n",
    "parallel\n",
    "```\n",
    "library(parallel)\n",
    "...\n",
    "results<-mclapply(nstarts, \n",
    "  function(nstart) kmeans(Boston, 4, nstart=nstart), \n",
    "  mc.cores=cores)\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## kmeans performance on farnam m610s\n",
    "\n",
    "   |runtime|s/u\n",
    "---|-------|-------\n",
    "1 node, 1 cpu| 44.475 | -\n",
    "1 node, 8 cpus | 5.96 | 7.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other thoughts on parallel R\n",
    "- _Parallel R_, by Steve Weston, O'Reilly Press\n",
    "- YCRC Bootcamp: Writing Efficient R Code (taught by Steve)\n",
    "- ```foreach``` parallel construct (written by Steve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Multiprocessing\n",
    "- Support for creating parallel processes and communicating and synchronizing\n",
    "- Simplest interface is parallel map, very similar to R's mclapply\n",
    "\n",
    "```\n",
    "import multiprocessing\n",
    "p=multiprocessing.Pool(10)\n",
    "inputs=[...]\n",
    "results=p.map(f, inputs)\n",
    "```\n",
    "\n",
    "- Pool creates set of \"workers\" that compute f() on inputs\n",
    "- Workers are forked processes.  Have copies of data at point where pool was created\n",
    "- Function, inputs, and outputs are serialized and passed between master and workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Travelling salesman in Python using multiprocessing\n",
    "- Given N cities, find shortest route visiting each once\n",
    "- NP-complete -> very expensive to find optimal solution\n",
    "- We'll use a heuristic approach, simulated annealing:\n",
    "\n",
    "```\n",
    "T = initialT\n",
    "curr = best = initialsolution\n",
    "while T > stopT:\n",
    "    candidate = randomly swap two adjacent cities in curr\n",
    "    if cost(candidate) < cost(best):\n",
    "        curr=candidate\n",
    "        best=candidate\n",
    "    elif cost(candidate)-cost(best) < T\n",
    "        curr=candidate\n",
    "    T = T * alpha\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization strategy\n",
    "- Run K copies, starting from different initial conditions\n",
    "- Take different random paths\n",
    "- Choose the best solution\n",
    "\n",
    "Example/simulated-annealing-tsp\n",
    "\n",
    "Steps:\n",
    "- seq.py: explicit for loop over simulations\n",
    "- map.py: convert loop to map\n",
    "- parmap.py: convert map to parallel map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parmap.py\n",
    "\n",
    "```\n",
    "def dotrial(t):\n",
    "    t.anneal()\n",
    "    return t\n",
    "\n",
    "p=multiprocessing.Pool(cores) \n",
    "trials = [SimAnneal(coords, ...) for i in range(ntrials)]\n",
    "got=p.map(dotrial, trials, chunksize=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C/C++: OpenMP\n",
    "- popular way to parallelize C programs on single node\n",
    "- annotate for loop with #pragma omp for \n",
    "\n",
    "```\n",
    "#pragma omp for reduction(+:sum)\n",
    "  for (i=0; i<len*threads; i++)\n",
    "    {\n",
    "      sum += (a[i] * b[i]);\n",
    "      psum = sum;\n",
    "    }\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtleties WRT random numbers\n",
    "- When running in parallel, what random number sequence is seen by each process?\n",
    "- many random number generators use system clock, which may not be different for each process\n",
    "- you may want reproduceable results\n",
    "\n",
    "\n",
    "\n",
    "- Python: ?\n",
    "- R: use RNGkind(\"L'Ecuyer-CMRG\")\n",
    "- Matlab: Each worker has same seed by default.  You should explicitly set it, e.g. rng(workerid)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
